{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "lovely-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vocal-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cross-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWords():\n",
    "    def __init__(self, stop_words=None):\n",
    "\n",
    "        self.stop_words = stop_words\n",
    "        self.vocabulary = set()\n",
    "        self.vocabulary_lookup = {}\n",
    "\n",
    "    \n",
    "    def fit(self, docs):\n",
    "        \n",
    "        docs = self._lower_docs(docs)\n",
    "        docs = self._remove_punct(docs)\n",
    "        docs = self._tokenize(docs)\n",
    "        docs = self._remove_stop_words(docs)\n",
    "        \n",
    "        self.vocab, self.vocab_lookup = self._create_vocab(docs)    \n",
    "    \n",
    "    \n",
    "    def _lower_docs(self, docs):\n",
    "        return [doc.lower().strip() for doc in docs]\n",
    "\n",
    "\n",
    "    def _remove_punct(self, docs):\n",
    "        return [doc.translate(str.maketrans('', '', string.punctuation)) \n",
    "                     for doc in docs]\n",
    "\n",
    "    def _tokenize(self, docs):\n",
    "        return [doc.split() for doc in docs]\n",
    "\n",
    "\n",
    "    def _remove_stop_words_from_doc(self, doc):\n",
    "        return [word for word in doc if word not in self.stop_words]\n",
    "\n",
    "\n",
    "    def _remove_stop_words(self, docs):\n",
    "        return [self._remove_stop_words_from_doc(doc) for doc in docs]\n",
    "\n",
    "\n",
    "    def _create_vocab(self, docs):\n",
    "        for doc in docs:\n",
    "            for token in doc:\n",
    "                self.vocabulary.add(token)\n",
    "\n",
    "        self.vocabulary_lookup = {word: i for i, word in enumerate(self.vocabulary)}\n",
    "\n",
    "        return self.vocabulary, self.vocabulary_lookup\n",
    "    \n",
    "    def transform(self, docs):\n",
    "        \n",
    "        docs = self._lower_docs(docs)\n",
    "        docs = self._remove_punct(docs)\n",
    "        docs = self._tokenize(docs)\n",
    "        docs = self._remove_stop_words(docs)\n",
    "        \n",
    "        return self._create_matrix(docs)\n",
    "    \n",
    "        \n",
    "    def _create_matrix(self, docs):\n",
    "    \n",
    "        self.matrix = np.zeros((len(docs), len(self.vocab)))\n",
    "\n",
    "        for doc_id, doc in enumerate(docs):\n",
    "            for token in doc:\n",
    "                word_id = self.vocabulary_lookup.get(token, None)\n",
    "                if word_id:\n",
    "                    self.matrix[doc_id][word_id] += 1\n",
    "                \n",
    "        return self.matrix\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, docs):\n",
    "        \n",
    "        self.fit(docs)\n",
    "        return self.transform(docs)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import numpy as np\n",
    "bow = BagOfWords(stop_words=stopwords.words('english'))\n",
    "y = bow.fit_transform(observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "metallic-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "filenames = []\n",
    "import os\n",
    "i = 0\n",
    "j=0\n",
    "d={}\n",
    "for directory in sorted(os.listdir('data/Converted sessions'))[:0:-1]:\n",
    "    d[directory] = len(os.listdir('data/Converted sessions/' + directory))\n",
    "    for filename in sorted(os.listdir('data/Converted sessions/' + directory)):\n",
    "        if filename.endswith('.txt'): #or filename.endswith('2016')\n",
    "            f = open('data/Converted sessions/' + directory + '/' + filename, \"r\")\n",
    "            docs.append(f.read())\n",
    "            filenames.append(filename[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "spectacular-glass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAT UZB\n",
      "182\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "for i, j in zip(filenames, x['ISO Code']):\n",
    "    if i!=j:\n",
    "        print(i,j)\n",
    "        print(k)\n",
    "        break\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "noble-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('data/Speakers_by_session.csv')\n",
    "x = x.replace('EU', 'EU_').drop(index=34).drop(index=153)\n",
    "# x[x['ISO Code'] == 'SGP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "underlying-practice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                                        2015.0\n",
       "Session                                       70.0\n",
       "ISO Code                                       SYC\n",
       "Country                                 Seychelles\n",
       "Name of Person Speaking    Mrs. Dalia GrybauskaitÄ—\n",
       "Post                                     President\n",
       "Language                                   English\n",
       "Notes                                          NaN\n",
       "Name: 166, dtype: object"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filenames[175], x['ISO Code'][175] #SWE - SYC\n",
    "x.iloc[164, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "minimal-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['I love you',\n",
    "       'hello how are you!',\n",
    "       'what is up!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "rising-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = BagofWords(sw)\n",
    "bow.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "quick-ticket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  0.0  1.0  1.0\n",
       "1  0.0  0.0  0.0\n",
       "2  0.0  0.0  0.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bow.fit_transform(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-electricity",
   "metadata": {},
   "source": [
    "create a simple test to ensure that your code is working as you think it is"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
